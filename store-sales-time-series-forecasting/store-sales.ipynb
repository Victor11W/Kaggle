{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abff8d6e",
   "metadata": {},
   "source": [
    "# Store Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0120562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victor\\Desktop\\Kaggle\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "# Désactive les erreurs Ray parasites\n",
    "os.environ[\"RAY_IGNORE_UNHANDLED_ERRORS\"] = \"1\"\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "holidays_events = pd.read_csv('holidays_events.csv')\n",
    "oil = pd.read_csv('oil.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "transactions = pd.read_csv('transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e75625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génère un rapport HTML pour chaque DataFrame CSV chargé\n",
    "if False:\n",
    "    ProfileReport(train, title=\"Profiling Report - train\").to_file(\"train_profile.html\")\n",
    "    ProfileReport(test, title=\"Profiling Report - test\").to_file(\"test_profile.html\")\n",
    "    ProfileReport(holidays_events, title=\"Profiling Report - holidays_events\").to_file(\"holidays_events_profile.html\")\n",
    "    ProfileReport(oil, title=\"Profiling Report - oil\").to_file(\"oil_profile.html\")\n",
    "    ProfileReport(stores, title=\"Profiling Report - stores\").to_file(\"stores_profile.html\")\n",
    "    ProfileReport(transactions, title=\"Profiling Report - transactions\").to_file(\"transactions_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b3dd83",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Remplace les valeurs manquantes dans 'dcoilwtico' par la moyenne des valeurs précédente et suivante\n",
    "oil['dcoilwtico'] = oil['dcoilwtico'].interpolate(method='linear', limit_direction='both')\n",
    "print(oil['dcoilwtico'].isnull().sum())  # Vérifie qu'il n'y a plus de valeurs manquantes\n",
    "\n",
    "# Ajoute le prix de l'oil dans train et test en fonction de la date\n",
    "train = train.merge(oil, on='date', how='left')\n",
    "test = test.merge(oil, on='date', how='left')\n",
    "\n",
    "# Complète les valeurs manquantes de dcoilwtico dans train et test par interpolation linéaire\n",
    "train['dcoilwtico'] = train['dcoilwtico'].interpolate(method='linear', limit_direction='both')\n",
    "test['dcoilwtico'] = test['dcoilwtico'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "# Ajoute une colonne 'day_of_week' indiquant le jour de la semaine (0=lundi, 6=dimanche)\n",
    "train['day_of_week'] = pd.to_datetime(train['date']).dt.dayofweek\n",
    "test['day_of_week'] = pd.to_datetime(test['date']).dt.dayofweek\n",
    "\n",
    "# One-hot encoding de la colonne 'day_of_week'\n",
    "train = pd.get_dummies(train, columns=['day_of_week'], prefix='dow')\n",
    "test = pd.get_dummies(test, columns=['day_of_week'], prefix='dow')\n",
    "\n",
    "# remplace la date par un entier représentant le jour depuis le début du dataset\n",
    "train['date'] = (pd.to_datetime(train['date']) - pd.to_datetime('2013-01-01')).dt.days\n",
    "test['date'] = (pd.to_datetime(test['date']) - pd.to_datetime('2013-01-01')).dt.days\n",
    "\n",
    "\n",
    "# Lag de 1 jour\n",
    "train[\"lag1_sales\"] = train.groupby([\"store_nbr\", \"family\"])[\"sales\"].shift(1)\n",
    "train_clean = train.dropna(subset=[\"lag1_sales\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ff6412",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  store_nbr      family  onpromotion  dcoilwtico  dow_0  dow_1  \\\n",
      "1782     1          1  AUTOMOTIVE            0       93.14  False  False   \n",
      "1783     1          1   BABY CARE            0       93.14  False  False   \n",
      "1784     1          1      BEAUTY            0       93.14  False  False   \n",
      "1785     1          1   BEVERAGES            0       93.14  False  False   \n",
      "1786     1          1       BOOKS            0       93.14  False  False   \n",
      "\n",
      "      dow_2  dow_3  dow_4  dow_5  dow_6  lag1_sales  \n",
      "1782   True  False  False  False  False         0.0  \n",
      "1783   True  False  False  False  False         0.0  \n",
      "1784   True  False  False  False  False         0.0  \n",
      "1785   True  False  False  False  False         0.0  \n",
      "1786   True  False  False  False  False         0.0  \n",
      "Colonnes catégorielles : ['store_nbr', 'family', 'dow_0', 'dow_1', 'dow_2', 'dow_3', 'dow_4', 'dow_5', 'dow_6']\n",
      "Colonnes numériques : ['date', 'dcoilwtico', 'lag1_sales', 'onpromotion']\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['id', 'sales']\n",
    "X = train_clean.drop(columns=drop_cols)\n",
    "y = train_clean['sales']\n",
    "\n",
    "print(X.head())\n",
    "\n",
    "cat_cols = ['store_nbr', 'family'] + [f'dow_{i}' for i in range(7)]\n",
    "num_cols = ['date','dcoilwtico', 'lag1_sales', 'onpromotion']\n",
    "print(\"Colonnes catégorielles :\", cat_cols)\n",
    "print(\"Colonnes numériques :\", num_cols)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # One-hot categorical features\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        # Pass-through numerical features\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"  # drop unused raw columns like Name, Ticket, Cabin, etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcdb7a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dcoilwtico     0\n",
      "dow_0          0\n",
      "dow_1          0\n",
      "dow_2          0\n",
      "dow_3          0\n",
      "dow_4          0\n",
      "dow_5          0\n",
      "dow_6          0\n",
      "lag1_sales     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False  \n",
    ")\n",
    "\n",
    "\n",
    "print(X.isnull().sum())\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "y_pred = np.maximum(0, y_pred)\n",
    "score = np.sqrt(mean_squared_log_error(y_valid, y_pred))\n",
    "print(\"RMSLE :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d59901",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    # features disponibles\n",
    "    X_test = test.loc[test.index[i], [\"lag1_sales\"]].values.reshape(1, -1)\n",
    "    \n",
    "    # prédiction\n",
    "    y_pred = model.predict(X_test)[0]\n",
    "    \n",
    "    # enregistrer\n",
    "    test.loc[test.index[i], \"sales\"] = y_pred\n",
    "    \n",
    "    # mettre à jour le lag du jour suivant\n",
    "    if i + 1 < len(test):\n",
    "        test.loc[test.index[i+1], \"lag1_sales\"] = y_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
